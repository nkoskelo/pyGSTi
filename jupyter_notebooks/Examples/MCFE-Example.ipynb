{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running MCFE on target circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygsti\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pyGSTi circs\n",
    "unmapped_circs = [pygsti.circuits.Circuit([[\"Gxpi2\", \"Q0\"], [\"Gypi2\", \"Q1\"]]),pygsti.circuits.Circuit([[\"Gypi2\", \"Q0\"], [\"Gxpi2\", \"Q1\"]])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map circuits to device connectivity and U3-CX gate set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step will be different depending on what architecture you are using. For this example, we are using an IBM device. You need to end up with pyGSTi circuits in a U3-CX gate set so that circuit mirroring can be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ndsieki/pygsti_development/pyGSTi/pygsti/circuits/circuit.py:4086: UserWarning: skipping barrier\n",
      "  _warnings.warn('skipping barrier')\n",
      "/home/ndsieki/pygsti_development/pyGSTi/pygsti/circuits/circuit.py:4082: UserWarning: skipping measure\n",
      "  _warnings.warn('skipping measure')\n"
     ]
    }
   ],
   "source": [
    "mapped_circs = defaultdict(list)\n",
    "\n",
    "import qiskit\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager as _pass_manager\n",
    "from qiskit_ibm_runtime.fake_provider import FakeSherbrooke, FakeAthensV2\n",
    "\n",
    "fake_backend = FakeAthensV2()\n",
    "\n",
    "pm = _pass_manager(coupling_map=fake_backend.coupling_map, basis_gates=['u3', 'cx'], optimization_level=0)\n",
    "\n",
    "\n",
    "for i, circ in enumerate(unmapped_circs):\n",
    "    # Convert from pyGSTi to Qiskit\n",
    "    # Comment these lines out and do qiskit_circ = circ if passing in Qiskit\n",
    "    pygsti_openqasm_circ = circ.convert_to_openqasm(block_between_layers=True, include_delay_on_idle=False)\n",
    "    # print(pygsti_openqasm_circ)\n",
    "    qiskit_circ = qiskit.QuantumCircuit.from_qasm_str(pygsti_openqasm_circ)\n",
    "\n",
    "    # print(qiskit_circ.draw())\n",
    "\n",
    "    mapped_qiskit_circ = pm.run(qiskit_circ)\n",
    "\n",
    "    # print(mapped_qiskit_circ.draw())\n",
    "    pygsti_circ = pygsti.circuits.Circuit.from_qiskit(mapped_qiskit_circ)\n",
    "    # print(pygsti_circ)\n",
    "\n",
    "    mapped_circ = pygsti_circ\n",
    "\n",
    "    metadata = {'width': len(mapped_circ.line_labels), 'physical_depth': mapped_circ.depth, 'dropped_gates': 0, 'id': i}\n",
    "    mapped_circs[mapped_circ] += [metadata]\n",
    "\n",
    "\n",
    "unmirrored_design = pygsti.protocols.FreeformDesign(mapped_circs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mirror circuit generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Pauli random compiling (`pauli_rc`) here. Central Pauli (`central_pauli`) is also an option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling mirror circuits:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using provided edesign for both reference and test compilations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling mirror circuits:  50%|#####     | 1/2 [00:00<00:00,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using provided edesign for both reference and test compilations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling mirror circuits: 100%|##########| 2/2 [00:00<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling reference circuits for width 5 with 1 subsets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling reference circuits for subset ('Q0', 'Q1', 'Q2', 'Q3', 'Q4'): 100%|##########| 100/100 [00:00<00:00, 2232.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mirroring time: 0.6630532741546631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Highly recommended to seed all RNG\n",
    "mcfe_rand_state = np.random.RandomState(20240718)\n",
    "\n",
    "start = time.time()\n",
    "mirror_design = pygsti.protocols.mirror_edesign.make_mirror_edesign(\n",
    "    unmirrored_design,\n",
    "    num_mcs_per_circ=100,\n",
    "    num_ref_per_qubit_subset=100,\n",
    "    mirroring_strategy='pauli_rc',\n",
    "    rand_state=mcfe_rand_state)\n",
    "print(f'Mirroring time:', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created the MCFE experiment design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Edesign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example will run the edesign on a fake IBM backend, but this is not strictly required. This step needs to generate a `ProtocolData(edesign=mirror_edesign, dataset=circuit_counts_data)` where `mirror_edesign` is the variable defined earlier and `circuit_counts_data` is a `DataSet` that contains the outcomes for each circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14238238334655762\n"
     ]
    }
   ],
   "source": [
    "from pygsti.extras.devices import ExperimentalDevice\n",
    "from pygsti.extras import devices, ibmq\n",
    "\n",
    "device = ExperimentalDevice.from_qiskit_backend(fake_backend)\n",
    "# device = ExperimentalDevice.from_legacy_device('ibm_brisbane')\n",
    "pspec = device.create_processor_spec(['Gc{}'.format(i) for i in range(24)] + ['Gcnot'])\n",
    "\n",
    "start = time.time()\n",
    "#exp = ibmq.IBMQExperiment(combined_mirror_design, pspec, circuits_per_batch=300, num_shots=1024, seed=20240718, disable_checkpointing=True)\n",
    "exp = ibmq.IBMQExperiment(mirror_design, pspec, circuits_per_batch=300, num_shots=1024, seed=20240718, checkpoint_override=True)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:17<00:00,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total transpilation time: 17.268017530441284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from qiskit_aer import AerSimulator\n",
    "\n",
    "sim_backend = AerSimulator.from_backend(fake_backend)\n",
    "\n",
    "qiskit_pass_kwargs = {\n",
    "    'optimization_level': 0,\n",
    "    'routing_method': 'none'\n",
    "}\n",
    "\n",
    "qasm_convert_kwargs = {\n",
    "    'num_qubits': pspec.num_qubits,\n",
    "    'standard_gates_version': 'x-sx-rz',\n",
    "    'include_delay_on_idle': True\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "exp.transpile(sim_backend, qiskit_pass_kwargs, qasm_convert_kwargs)\n",
    "end = time.time()\n",
    "print(f'Total transpilation time: {end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting batch 1\n",
      "  - Job ID is 0d0c4c76-ba08-4a5e-8250-63c37651c54d\n",
      "  - Failed to get queue position for batch 1\n",
      "Submitting batch 2\n",
      "  - Job ID is bc708a2c-0e8d-4359-a229-a4b5f2a871c6\n",
      "  - Failed to get queue position for batch 2\n"
     ]
    }
   ],
   "source": [
    "exp.submit(sim_backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying IBMQ for results objects for batch 1...\n",
      "Querying IBMQ for results objects for batch 2...\n",
      "16.18717908859253\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "exp.batch_results = []\n",
    "exp.retrieve_results()\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = exp.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute process fidelity for each circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below contains functions that ultimately compute a dataframe containing the process fidelities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "def hamming_distance_counts(dsrow, circ, idealout):\n",
    "    nQ = len(circ.line_labels)  # number of qubits\n",
    "    assert(nQ == len(idealout[-1]))\n",
    "    hamming_distance_counts = np.zeros(nQ + 1, float)\n",
    "    if dsrow.total > 0:\n",
    "        for outcome_lbl, counts in dsrow.counts.items():\n",
    "            outbitstring = outcome_lbl[-1]\n",
    "            hamming_distance_counts[pygsti.tools.rbtools.hamming_distance(outbitstring, idealout[-1])] += counts\n",
    "    return hamming_distance_counts\n",
    "\n",
    "def adjusted_success_probability(hamming_distance_counts):\n",
    "    if np.sum(hamming_distance_counts) == 0.: \n",
    "        return 0.\n",
    "    else:\n",
    "        hamming_distance_pdf = np.array(hamming_distance_counts) / np.sum(hamming_distance_counts)\n",
    "        adjSP = np.sum([(-1 / 2)**n * hamming_distance_pdf[n] for n in range(len(hamming_distance_pdf))])\n",
    "        return adjSP\n",
    "\n",
    "def effective_polarization(hamming_distance_counts):\n",
    "    n = len(hamming_distance_counts) - 1 \n",
    "    asp = adjusted_success_probability(hamming_distance_counts)\n",
    "    \n",
    "    return (4**n * asp - 1)/(4**n - 1)\n",
    "\n",
    "def polarization_to_fidelity(p, n): \n",
    "    return 1 - (4**n - 1)*(1 - p)/4**n\n",
    "\n",
    "def fidelity_to_polarization(f, n):\n",
    "    return 1 - (4**n)*(1 - f)/(4**n - 1)\n",
    "\n",
    "def predicted_process_fidelity(bare_rc_effective_pols, rc_rc_effective_pols, reference_effective_pols, n):\n",
    "\n",
    "    a = np.mean(bare_rc_effective_pols)\n",
    "    b = np.mean(rc_rc_effective_pols)\n",
    "    c = np.mean(reference_effective_pols)\n",
    "    if c <= 0.:\n",
    "        return np.nan  # raise ValueError(\"Reference effective polarization zero or smaller! Cannot estimate the process fidelity\")\n",
    "    elif b <= 0:\n",
    "        return 0.\n",
    "    else:\n",
    "        return polarization_to_fidelity(a / np.sqrt(b * c), n)\n",
    "\n",
    "def predicted_process_fidelity_for_central_pauli_mcs(central_pauli_effective_pols, reference_effective_pols, n):\n",
    "    a = np.mean(central_pauli_effective_pols)\n",
    "    c = np.mean(reference_effective_pols)\n",
    "    if c <= 0.:\n",
    "        return np.nan  # raise ValueError(\"Reference effective polarization zero or smaller! Cannot estimate the process fidelity\")\n",
    "    elif a <= 0:\n",
    "        return 0.\n",
    "    else:\n",
    "        return polarization_to_fidelity(np.sqrt(a / c), n)\n",
    "    \n",
    "def calculate_vb_df(unmirrored_design, mirrored_data, verbose=True):\n",
    "    # Run through and calculate all effective polarizations\n",
    "    eff_pols = {k: {} for k in mirrored_data.edesign.keys()}\n",
    "    \n",
    "    # Stats about the base circuit\n",
    "    u3_densities = {}\n",
    "    cnot_densities = {}\n",
    "    cnot_counts = {}\n",
    "    cnot_depths = {}\n",
    "    pygsti_depths = {}\n",
    "    idling_qubits = {}\n",
    "    dropped_gates = {}\n",
    "    occurrences = {}\n",
    "\n",
    "    # Get a dict going from id to circuit for easy lookup\n",
    "    reverse_circ_ids = {}\n",
    "    for k,v in unmirrored_design.aux_info.items():\n",
    "        if isinstance(v, dict):\n",
    "            reverse_circ_ids[v['id']] = k\n",
    "        else:\n",
    "            for entry in v:\n",
    "                reverse_circ_ids[entry['id']] = k\n",
    "    seen_keys = set()\n",
    "\n",
    "    num_circs = len(mirrored_data.dataset)\n",
    "    for c in tqdm.tqdm(mirrored_data.dataset, ascii=True, desc='Calculating effective polarizations'):\n",
    "        for edkey, ed in mirrored_data.edesign.items():\n",
    "            auxlist = ed.aux_info.get(c, None)\n",
    "            if auxlist is None:\n",
    "                continue\n",
    "            elif isinstance(auxlist, dict):\n",
    "                auxlist = [auxlist]\n",
    "\n",
    "            for aux in auxlist:\n",
    "                if edkey.endswith('ref'):\n",
    "                    # For reference circuits, only width matters, so aggregate on that now\n",
    "                    key = aux['width']\n",
    "                else:\n",
    "                    key = (aux['base_aux']['width'], aux['base_aux']['physical_depth'], aux['base_aux']['id'])\n",
    "\n",
    "                \n",
    "                # Calculate effective polarization\n",
    "                hdc = hamming_distance_counts(mirrored_data.dataset[c], c, (aux['idealout'],))\n",
    "                ep = effective_polarization(hdc)\n",
    "                \n",
    "                # Append to other mirror circuit samples\n",
    "                eps = eff_pols[edkey].get(key, [])\n",
    "                eps.append(ep)\n",
    "                eff_pols[edkey][key] = eps\n",
    "\n",
    "                if edkey.endswith('ref') or key in seen_keys:\n",
    "                    # Skip statistic gathering for reference circuits or base circuits we've seen already\n",
    "                    continue\n",
    "\n",
    "                orig_circ = reverse_circ_ids[key[2]]\n",
    "\n",
    "                u3_count = 0\n",
    "                cnot_count = 0\n",
    "                cnot_depth = 0\n",
    "                for i in range(orig_circ.depth):\n",
    "                    layer_cnot_depth = 0\n",
    "                    for gate in orig_circ._layer_components(i):\n",
    "                        if gate.name == 'Gu3':\n",
    "                            u3_count += 1\n",
    "                        elif gate.name == 'Gcnot':\n",
    "                            cnot_count += 2\n",
    "                            layer_cnot_depth = 1\n",
    "                    cnot_depth += layer_cnot_depth\n",
    "                \n",
    "                if cnot_count == 0:\n",
    "                    cnot_count = 0.01\n",
    "                    \n",
    "                u3_densities[key] = u3_count / (key[0]*key[1])\n",
    "                cnot_densities[key] = cnot_count / (key[0]*key[1])\n",
    "                cnot_counts[key] = cnot_count / 2 # Want 1 for each CNOT\n",
    "                cnot_depths[key] = cnot_depth\n",
    "                pygsti_depths[key] = orig_circ.depth\n",
    "                idling_qubits[key] = len(orig_circ.idling_lines())\n",
    "                dropped_gates[key] = aux['base_aux']['dropped_gates']\n",
    "                occurrences[key] = len(auxlist)\n",
    "\n",
    "                seen_keys.add(key)\n",
    "\n",
    "    # Calculate process fidelities\n",
    "    df_data = {}\n",
    "    for i, key in enumerate(sorted(list(seen_keys), key=lambda x: x[2])):\n",
    "        cp_pfid = cp_pol = cp_success_prob = None\n",
    "        if 'cp' in mirrored_data.edesign and 'cpref' in mirrored_data.edesign:\n",
    "            if verbose and i == 0: print('Central pauli data detected, computing CP process fidelity')\n",
    "            cp_pfid = predicted_process_fidelity_for_central_pauli_mcs(eff_pols['cp'][key], eff_pols['cpref'][key[0]], key[0])\n",
    "            cp_pol = polarization_to_fidelity(cp_pfid, key[0])\n",
    "            cp_success_prob = pygsti.protocols.vbdataframe.polarization_to_success_probability(cp_pol, key[0])\n",
    "            \n",
    "        rc_pfid = rc_pol = rc_success_prob = None\n",
    "        if 'rr' in mirrored_data.edesign and 'br' in mirrored_data.edesign and 'ref' in mirrored_data.edesign:\n",
    "            if verbose and i == 0: print('Random compilation data detected, computing RC process fidelity')\n",
    "            rc_pfid = predicted_process_fidelity(eff_pols['br'][key], eff_pols['rr'][key], eff_pols['ref'][key[0]], key[0])\n",
    "            rc_pol = polarization_to_fidelity(rc_pfid, key[0])\n",
    "            rc_success_prob = pygsti.protocols.vbdataframe.polarization_to_success_probability(rc_pol, key[0])\n",
    "\n",
    "        # Depth is doubled for conventions (same happens for RMC/PMC)\n",
    "        df_data[i] = {'Width': key[0], 'Physical Depth': key[1], 'Circuit Id': key[2],\n",
    "                      'U3 Density': u3_densities[key], 'CNOT Density': cnot_densities[key],\n",
    "                      'CNOT Counts': cnot_counts[key], 'CNOT Depth': cnot_depths[key],\n",
    "                      'U3+CNOT Depth': pygsti_depths[key], 'Dropped Gates': dropped_gates[key],\n",
    "                      'Effective Width': key[0] - idling_qubits[key],\n",
    "                      'CP Process Fidelity': cp_pfid, 'CP Polarization': cp_pol,\n",
    "                      'CP Success Probability': cp_success_prob,\n",
    "                      'RC Process Fidelity': rc_pfid, 'RC Polarization': rc_pol,\n",
    "                      'RC Success Probability': rc_success_prob,\n",
    "                      'Occurrences': occurrences[key], 'Total Counts': 1024}\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame.from_dict(df_data, orient='index')\n",
    "    df = df.sort_values(by='Circuit Id')\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating effective polarizations: 100%|##########| 500/500 [00:00<00:00, 2724.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random compilation data detected, computing RC process fidelity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = calculate_vb_df(unmirrored_design, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you used Central Pauli instead, you can swap `'RC Process Fidelity'` for `'CP Process Fidelity'` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_fidelities = df['RC Process Fidelity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9950162628750925, 0.9961010286172316]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_fidelities.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pygsti_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
