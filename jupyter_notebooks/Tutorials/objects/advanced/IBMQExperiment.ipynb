{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running experiments on IBM Q Processors\n",
    "This tutorial will demonstrate how to run an experiment on IBM Q Processors. To do so you will need [QisKit](https://qiskit.org/) installed and an [IBM Q account](https://quantum-computing.ibm.com/).\n",
    "\n",
    "<font style=\"color:red\">There have been major changes to `IBMQExperiment` as of pygsti 0.9.13. This is due to Qiskit 1.0 and subsequent deprecations of V1 backends and `qiskit-ibm-provider`. The `IBMQExperiment` class only supports V2 backends and is based on `qiskit-ibm-runtime`.\n",
    "\n",
    "For details on how to migrate from `qiskit<1` or `qiskit-ibm-provider`, see [this blog post](https://www.ibm.com/quantum/blog/transition-to-1), [this Qiskit 1.0 migration guide](https://docs.quantum.ibm.com/api/migration-guides/qiskit-1.0-features), or [this Qiskit Runtime migration guide](https://docs.quantum.ibm.com/api/migration-guides/qiskit-runtime).</font>\n",
    "\n",
    "This was last run with QisKit versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiskit.__version__ = '1.1.1'\n",
    "#qiskit_ibm_runtime.__version__ = '0.25.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pygsti\n",
    "from pygsti.extras.devices import ExperimentalDevice\n",
    "from pygsti.extras import ibmq\n",
    "from pygsti.processors import CliffordCompilationRules as CCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "from qiskit_ibm_runtime.fake_provider import FakeSherbrooke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load your IBM Q access\n",
    "First, load you IBM Q account, get your `provider` and select a device. To do this, follow IBM Q's instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your first time, you may need to initialize your account with your IBMQ API token\n",
    "\n",
    "# You can also specify instances (i.e. \"ibm-q/open/main\" is the default instance)\n",
    "# You can also save/load named accounts for different instances, etc. See save_account docs for more information.\n",
    "\n",
    "#QiskitRuntimeService.save_account(channel=\"ibm_quantum\", token=\"<IQP_TOKEN>\", overwrite=True, set_as_default=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once credentials are saved, the service can be loaded each time:\n",
    "service = QiskitRuntimeService(channel=\"ibm_quantum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<IBMBackend('ibm_brisbane')>,\n",
       " <IBMBackend('ibm_cusco')>,\n",
       " <IBMBackend('ibm_fez')>,\n",
       " <IBMBackend('ibm_kyiv')>,\n",
       " <IBMBackend('ibm_kyoto')>,\n",
       " <IBMBackend('ibm_nazca')>,\n",
       " <IBMBackend('ibm_osaka')>,\n",
       " <IBMBackend('ibm_sherbrooke')>,\n",
       " <IBMBackend('ibm_torino')>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can list all the available backends to ensure your instance is running properly\n",
    "service.backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "# Can use a physical device...\n",
    "#backend = service.backend('ibm_sherbrooke')\n",
    "\n",
    "# Can also ask for the least busy physical device\n",
    "backend = service.least_busy()\n",
    "\n",
    "# ... or can use a simulated fake backend\n",
    "sim_backend = FakeSherbrooke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IBMBackend('ibm_osaka')>\n"
     ]
    }
   ],
   "source": [
    "# Let's see which backend is the least busy!\n",
    "print(backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a ProcessorSpec for IBM Q's processor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a ProcessorSpec for the device you're going to run on. This ProcessorSpec must also contain the details needed for creating the pyGSTi experiment design that you want to run, which you can tweak by varying the optional arguments to the `devices.create_processor_spec()` function.\n",
    "\n",
    "In `v0.9.12`, the `pygsti.extras.devices` module has been updated. You can still use the existing files in `pygsti.extras.devices` if you are offline, and thus may still want to add your own device files. However, you can now also simply use the IBMQ backend to create an `ExperimentalDevice` which is compatible with ProcessorSpecs and Models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "# Using the configuration files in pygsti.extras.devices (legacy and may not be up-to-date)\n",
    "#device = ExperimentalDevice.from_legacy_device('ibmq_bogota')\n",
    "\n",
    "# Using the active backend to pull current device specification\n",
    "device = ExperimentalDevice.from_qiskit_backend(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pspec = device.create_processor_spec(['Gc{}'.format(i) for i in range(24)] + ['Gcnot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an ExperimentDesign\n",
    "Next we create an `ExperimentDesign` that specifies the circuits you want to run on that device. Here we create a very simple mirror circuit benchmarking experiment. We'll use randomized mirror circuits, constructed using a `MirrorRBDesign`.\n",
    "\n",
    "First we pick the circuit design parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected qubits ['Q18', 'Q0', 'Q14', 'Q1'] for device ibm_osaka\n",
      "total circuits: 160\n",
      "full total circuits: 160\n"
     ]
    }
   ],
   "source": [
    "#circuit design parameters\n",
    "depths = [0, 2, 4, 16]\n",
    "circuits_per_shape = 10\n",
    "\n",
    "# dict setting the circuit widths (# qubits) you want to probe \n",
    "# and the qubits you want to use at each width\n",
    "# You can use device.graph.edges() to make sure these are connected components\n",
    "def get_N_connected_qubits(device, N, starting_qubits = None):\n",
    "    if starting_qubits is None:\n",
    "        starting_qubits = []\n",
    "    qubits = set(starting_qubits)\n",
    "\n",
    "    for edge in device.graph.edges():\n",
    "        # Check if connected, and add if so\n",
    "        if not len(qubits) or edge[0] in qubits or edge[1] in qubits:\n",
    "            qubits.update(edge)\n",
    "        \n",
    "        # Check if we can break\n",
    "        if len(qubits) >= N:\n",
    "            break\n",
    "    \n",
    "    return list(qubits)[:N]\n",
    "\n",
    "max_width = 4\n",
    "selected_qubits = get_N_connected_qubits(device, max_width)\n",
    "print(f\"Selected qubits {selected_qubits} for device {backend.name}\")\n",
    "\n",
    "qubit_lists = {}\n",
    "for i in range(max_width):\n",
    "    qubit_lists[i] = [tuple(selected_qubits[:i+1])]\n",
    "\n",
    "widths = list(qubit_lists.keys())\n",
    "\n",
    "print('total circuits: {}'.format(circuits_per_shape*len(widths)*len(depths)))\n",
    "total_circuits = 0\n",
    "for w in widths:\n",
    "    total_circuits += len(qubit_lists[w]) * circuits_per_shape * len(depths)\n",
    "print('full total circuits: {}'.format(total_circuits) )\n",
    "\n",
    "# We'll use the `edgegrab` sampler, which requires specifying the expected number\n",
    "# of two-qubit gates per random layer.\n",
    "twoQmean = {w:w/8 for w in widths}\n",
    "if 1 in widths: twoQmean[1] = 0 # No two-qubit gates in one-qubit circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to do Mirror RB, we need some Clifford compilations. See the RB-MirrorRB tutorial for more details.\n",
    "compilations = {'absolute': CCR.create_standard(pspec, 'absolute', ('paulis', '1Qcliffords'), verbosity=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Sampling 10 circuits at MRB length 0 (1 of 4 depths) with seed 311034\n",
      "- Sampling 10 circuits at MRB length 2 (2 of 4 depths) with seed 311044\n",
      "- Sampling 10 circuits at MRB length 4 (3 of 4 depths) with seed 311054\n",
      "- Sampling 10 circuits at MRB length 16 (4 of 4 depths) with seed 311064\n",
      "- Sampling 10 circuits at MRB length 0 (1 of 4 depths) with seed 761560\n",
      "- Sampling 10 circuits at MRB length 2 (2 of 4 depths) with seed 761570\n",
      "- Sampling 10 circuits at MRB length 4 (3 of 4 depths) with seed 761580\n",
      "- Sampling 10 circuits at MRB length 16 (4 of 4 depths) with seed 761590\n",
      "- Sampling 10 circuits at MRB length 0 (1 of 4 depths) with seed 84715\n",
      "- Sampling 10 circuits at MRB length 2 (2 of 4 depths) with seed 84725\n",
      "- Sampling 10 circuits at MRB length 4 (3 of 4 depths) with seed 84735\n",
      "- Sampling 10 circuits at MRB length 16 (4 of 4 depths) with seed 84745\n",
      "- Sampling 10 circuits at MRB length 0 (1 of 4 depths) with seed 117582\n",
      "- Sampling 10 circuits at MRB length 2 (2 of 4 depths) with seed 117592\n",
      "- Sampling 10 circuits at MRB length 4 (3 of 4 depths) with seed 117602\n",
      "- Sampling 10 circuits at MRB length 16 (4 of 4 depths) with seed 117612\n"
     ]
    }
   ],
   "source": [
    "edesigns_dict = {}\n",
    "edesign_index = 1\n",
    "for w in widths:\n",
    "    for qubits in qubit_lists[w]:\n",
    "        sub_edesign = pygsti.protocols.MirrorRBDesign(pspec, depths, circuits_per_shape, qubit_labels=qubits,\n",
    "                                                      clifford_compilations=compilations, sampler='edgegrab', samplerargs=[twoQmean[w],])\n",
    "        \n",
    "        edesigns_dict[str(edesign_index)] = sub_edesign\n",
    "        edesign_index += 1\n",
    "        \n",
    "combined_edesign = pygsti.protocols.CombinedExperimentDesign(edesigns_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on IBM Q\n",
    "We're now ready to run on the IBM Q processor. We do this using an `IBMQExperiment` object.\n",
    "\n",
    "We can enable checkpointing for `IBMQExperiment` objects by providing a path. This is the default and is recommended! We are also overriding old checkpoints here to ensure we have a clean starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "exp = ibmq.IBMQExperiment(combined_edesign, pspec, circuits_per_batch=75, num_shots=1024, seed=20231201,\n",
    "                          checkpoint_path='test_ibmq', checkpoint_override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we convert pyGSTi circuits into jobs that can be submitted to IBM Q. **This step includes transpiling of the pyGSTi circuits into OpenQASM** (and then into QisKit objects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transpiling circuit batch 1/3\n",
      "Transpiling circuit batch 2/3\n",
      "Transpiling circuit batch 3/3\n"
     ]
    }
   ],
   "source": [
    "# There is a Qiskit transpilation step than can be fully controlled with this argument\n",
    "qiskit_pass_kwargs = {\n",
    "    'optimization_level': 0, # Required (0 is default if not given)\n",
    "    'seed_transpiler': 12345, # Can provide a seed for any stochastic part (provided by default if not given)\n",
    "    'basis_gates': backend.operation_names # We want to make sure we compile to our backend gates\n",
    "}\n",
    "\n",
    "# There is a pyGSTi -> QASM -> Qiskit step that can be fully controlled with this argument\n",
    "qasm_convert_kwargs = {\n",
    "    'num_qubits': pspec.num_qubits, # This is the default is not given. May want to change this if using a simulated backend (127 qubits not feasible)\n",
    "    'standard_gates_version': 'x-sx-rz', # This is the default if not given\n",
    "}\n",
    "\n",
    "exp.transpile(backend, qiskit_pass_kwargs, qasm_convert_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already completed transpilation of 2/3 circuit batches\n",
      "Transpiling circuit batch 3/3\n"
     ]
    }
   ],
   "source": [
    "# We can simulate having been interrupted by removing the last few transpiled batches\n",
    "del exp.qiskit_isa_circuit_batches[2:]\n",
    "\n",
    "# And now transpilation should only redo the missing batches\n",
    "# We don't need to reprovide the options as they are saved by the first transpile call\n",
    "exp.transpile(backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the `IBMQExperiment` object is lost and needs to be reloaded (i.e. notebook restarts), it can be loaded from file now.\n",
    "\n",
    "However, the Qiskit circuits are not automatically regenerated from the transpiled QASM during loading for speed. They can (and need to be regenerated if calling `submit()`) by passing in the `regen_circs=True` flag to `from_dir()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transpiling circuit batch 1/3\n",
      "Transpiling circuit batch 2/3\n",
      "Transpiling circuit batch 3/3\n"
     ]
    }
   ],
   "source": [
    "exp2 = ibmq.IBMQExperiment.from_dir('test_ibmq', regen_circs=True, ibmq_backend=backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to submit this experiment to IBM Q.Note that we can submit using a different backend than what was used to generate the experiment design. In general, it is not a good idea to mix and match backends for physical devices unless they have the exact same connectivity and qubit labeling; however, it **is** often useful for debugging purposes to use the simulator backend rather than a physical device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting batch 1\n",
      "  - Job ID is ctb2we1c2sk0008c3r0g\n",
      "  - Failed to get queue position for batch 1\n",
      "    (because queue position not available in RuntimeJobV2)\n",
      "Submitting batch 2\n",
      "  - Job ID is ctb2weh0jacg008w6b3g\n",
      "  - Failed to get queue position for batch 2\n",
      "    (because queue position not available in RuntimeJobV2)\n",
      "Submitting batch 3\n",
      "  - Job ID is ctb2wf10jacg008w6b40\n",
      "  - Failed to get queue position for batch 3\n",
      "    (because queue position not available in RuntimeJobV2)\n"
     ]
    }
   ],
   "source": [
    "exp2.submit(backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then monitor the jobs. If get an error message, you can query the error using `exp.qjobs[i].error_message()` for batch `i`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: QUEUED\n",
      "  - Unable to retrieve queue position\n",
      "    (because queue position not available in RuntimeJobV2)\n",
      "Batch 2: QUEUED\n",
      "  - Unable to retrieve queue position\n",
      "    (because queue position not available in RuntimeJobV2)\n",
      "Batch 3: QUEUED\n",
      "  - Unable to retrieve queue position\n",
      "    (because queue position not available in RuntimeJobV2)\n"
     ]
    }
   ],
   "source": [
    "exp2.monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the `IBMQExperiment` can be loaded from file if checkpointing is being used. The Qiskit RuntimeJobs are not serialized; however, they can be retrieved from the IBMQ service from their job ids. In order to do this, pass `regen_jobs=True` and a `service` to the `from_dir()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading job 1/3...\n",
      "Loading job 2/3...\n",
      "Loading job 3/3...\n"
     ]
    }
   ],
   "source": [
    "exp3 = ibmq.IBMQExperiment.from_dir('test_ibmq', regen_jobs=True, service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: QUEUED\n",
      "  - Unable to retrieve queue position\n",
      "    (because queue position not available in RuntimeJobV2)\n",
      "Batch 2: QUEUED\n",
      "  - Unable to retrieve queue position\n",
      "    (because queue position not available in RuntimeJobV2)\n",
      "Batch 3: QUEUED\n",
      "  - Unable to retrieve queue position\n",
      "    (because queue position not available in RuntimeJobV2)\n"
     ]
    }
   ],
   "source": [
    "exp3.monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then grab the results, **Once you see that all the jobs are complete** (`.retrieve_results()` will just hang if the jobs have not yet completed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timestamps': {'created': '2024-07-16T08:24:24.760197Z',\n",
       "  'finished': None,\n",
       "  'running': None},\n",
       " 'bss': {'seconds': 0},\n",
       " 'usage': {'quantum_seconds': 0, 'seconds': 0},\n",
       " 'qiskit_version': 'qiskit_ibm_runtime-0.25.0,qiskit-1.1.1*',\n",
       " 'estimated_start_time': '2024-07-16T08:34:59.956Z',\n",
       " 'estimated_completion_time': '2024-07-16T08:38:20.956Z',\n",
       " 'caller': 'qiskit_ibm_runtime~sampler.py'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp3.qjobs[0].metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-16 01:34:59.956000-07:00\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.fromisoformat('2024-07-16T08:34:59.956Z').astimezone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying IBMQ for results objects for batch 1...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexp3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/repos/pyGSTi/pygsti/extras/ibmq/ibmqexperiment.py:281\u001b[0m, in \u001b[0;36mIBMQExperiment.retrieve_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m qjob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqjobs[exp_idx]\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuerying IBMQ for results objects for batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 281\u001b[0m batch_result \u001b[38;5;241m=\u001b[39m \u001b[43mqjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_results\u001b[38;5;241m.\u001b[39mappend(batch_result\u001b[38;5;241m.\u001b[39mto_dict())\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_checkpointing:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pygsti/lib/python3.12/site-packages/qiskit_ibm_runtime/runtime_job_v2.py:136\u001b[0m, in \u001b[0;36mRuntimeJobV2.result\u001b[0;34m(self, timeout, decoder)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the results of the job.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    RuntimeInvalidStateError: If the job was cancelled, and attempting to retrieve result.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    135\u001b[0m _decoder \u001b[38;5;241m=\u001b[39m decoder \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_result_decoder\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_final_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    138\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reason \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reason \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_message\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pygsti/lib/python3.12/site-packages/qiskit_ibm_runtime/runtime_job_v2.py:257\u001b[0m, in \u001b[0;36mRuntimeJobV2.wait_for_final_state\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m timeout:\n\u001b[1;32m    254\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m RuntimeJobTimeoutError(\n\u001b[1;32m    255\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimed out waiting for job to complete after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m secs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m             )\n\u001b[0;32m--> 257\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m         status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus()\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m futures\u001b[38;5;241m.\u001b[39mTimeoutError:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp3.retrieve_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `IBMQExperiment` object now contains the results of your experiment. It contains much of the information about exactly what was submitted to IBM Q, and raw results objects that IBM Q returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "display(exp3.qjobs)\n",
    "display(exp3.batch_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, most importantly, it contains the data formatted into a pyGSTi `ProtocolData` object, which is the packaged-up data that pyGSTi analysis proctols use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "data = exp3.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the results\n",
    "Because `retrieve_results()` has formatted the data into a `ProctocolData` object, we can just hand this to the analysis protocol(s) that are designed for analyzing this type of data. Here we'll analyze this data using a standard RB curve-fitting analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "rb = pygsti.protocols.RandomizedBenchmarking(datatype='adjusted_success_probabilities', defaultfit='A-fixed')\n",
    "results = {}\n",
    "for key in data.keys():\n",
    "    results[key] = rb.run(data[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "ws = pygsti.report.Workspace()\n",
    "ws.init_notebook_mode(autodisplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "for i in data.keys(): \n",
    "    print(i)\n",
    "    ws.RandomizedBenchmarkingPlot(results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
